{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "566dc171-6208-40cc-b3aa-bdf05a06187c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20030219</td>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20030219</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20030219</td>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date                                      headline_text\n",
       "0      20030219  aba decides against community broadcasting lic...\n",
       "1      20030219     act fire witnesses must be aware of defamation\n",
       "2      20030219     a g calls for infrastructure protection summit\n",
       "3      20030219           air nz staff in aust strike for pay rise\n",
       "4      20030219      air nz strike to affect australian travellers"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#news headlines published over a period of 15 years form kaggle\n",
    "import pandas as pd\n",
    "data = pd.read_csv('abcnews-date-text.csv', error_bad_lines=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c56c052-c281-4549-88d1-932366d15a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1226258"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88d1965e-0d61-4d38-b2d8-274374ffacd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       headline_text\n",
       "0  aba decides against community broadcasting lic...\n",
       "1     act fire witnesses must be aware of defamation\n",
       "2     a g calls for infrastructure protection summit\n",
       "3           air nz staff in aust strike for pay rise\n",
       "4      air nz strike to affect australian travellers"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking 1000 documents\n",
    "data_text=data[['headline_text']][:1000]\n",
    "data_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01a20109-bb1c-495a-899c-a00da47eb840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       headline_text  index\n",
       "0  aba decides against community broadcasting lic...      0\n",
       "1     act fire witnesses must be aware of defamation      1\n",
       "2     a g calls for infrastructure protection summit      2\n",
       "3           air nz staff in aust strike for pay rise      3\n",
       "4      air nz strike to affect australian travellers      4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_text['index']=data_text.index\n",
    "data_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aa6e213-eadc-46e6-91bc-bdb6eabeac18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b483c7cf-d655-4de5-8497-80bd4792f366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      aba decides against community broadcasting lic...\n",
       "1         act fire witnesses must be aware of defamation\n",
       "2         a g calls for infrastructure protection summit\n",
       "3               air nz staff in aust strike for pay rise\n",
       "4          air nz strike to affect australian travellers\n",
       "                             ...                        \n",
       "995                  conference to focus on tuna fishery\n",
       "996                        council hosts farewell for mp\n",
       "997                  council resists eba roster pressure\n",
       "998                     customs house restoration opened\n",
       "999                dam water levels still critically low\n",
       "Name: headline_text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_text['headline_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9ff53bd-62f1-461f-90fe-6e575fb91d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning data_text as documents\n",
    "documents=data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e6b92ab-6721-44f7-b900-8a592ece13be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c68aa780-5277-4a09-ab24-ebbdf46b8166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       headline_text  index\n",
      "0  aba decides against community broadcasting lic...      0\n",
      "1     act fire witnesses must be aware of defamation      1\n",
      "2     a g calls for infrastructure protection summit      2\n",
      "3           air nz staff in aust strike for pay rise      3\n",
      "4      air nz strike to affect australian travellers      4\n"
     ]
    }
   ],
   "source": [
    "print(documents[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1946c098-3bdb-47a7-99ac-407ef974ece8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srini\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\srini\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess # convert a document into a list of tokens\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk import PorterStemmer\n",
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5b03b9f-c059-45a7-bc07-76b4b02b0c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import re\\n\\nimport nltk\\nfrom nltk.corpus import stopwords\\n\\nfrom nltk.stem import WordNetLemmatizer\\nlemmatizer=WordNetLemmatizer()\\n\\nlist=[]\\nfor i in range(len(data_text)):\\n    review=re.sub('[^a-zA-Z]', ' ', data_text['headline_text'][i])\\n    review=review.lower()\\n    review=review.split()\\n    review= [lemmatizer.lemmatize(word) for word in review if word not in (stopwords.words('english'))]\\n    review=' '.join(review)\\n    list.append(review) \""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "list=[]\n",
    "for i in range(len(data_text)):\n",
    "    review=re.sub('[^a-zA-Z]', ' ', data_text['headline_text'][i])\n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    review= [lemmatizer.lemmatize(word) for word in review if word not in (stopwords.words('english'))]\n",
    "    review=' '.join(review)\n",
    "    list.append(review) \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c56997f4-557c-44ff-a185-138b59787e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6f632a1-f67d-40a5-b0ad-a94e53ae39b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>more water restrictions predicted for northern...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        headline_text  index\n",
       "99  more water restrictions predicted for northern...     99"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[documents['index'] == 99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5bc9ff6-8e38-4dc5-a692-fa809a6b66ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['more', 'water', 'restrictions', 'predicted', 'for', 'northern', 'tas']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['water', 'restrict', 'predict', 'northern']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 99].values[0][0]\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f1726ee-6efa-4841-a4c9-d1d1587fb3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               [decid, commun, broadcast, licenc]\n",
       "1                               [wit, awar, defam]\n",
       "2           [call, infrastructur, protect, summit]\n",
       "3                      [staff, aust, strike, rise]\n",
       "4             [strike, affect, australian, travel]\n",
       "5               [ambiti, olsson, win, tripl, jump]\n",
       "6           [antic, delight, record, break, barca]\n",
       "7    [aussi, qualifi, stosur, wast, memphi, match]\n",
       "8            [aust, address, secur, council, iraq]\n",
       "9                         [australia, lock, timet]\n",
       "Name: headline_text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = documents['headline_text'].map(preprocess)\n",
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbb9fabb-1c3d-4711-b1c6-22c78c017d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Dictionary encapsulates the mapping between normalized words and their integer ids.\n",
    "\n",
    "#The main function is doc2bow, which converts a collection of words to its bag-of-words representation: a list of (word_id, word_frequency) 2-tuples.\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "975456d8-9671-4b51-b3fa-bf47bbf429f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(275, 1), (609, 1), (1212, 1), (1437, 1), (1720, 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "095d7406-cdd4-4980-a01f-69f6a037819b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5081330240297587),\n",
      " (1, 0.4057017483173504),\n",
      " (2, 0.5648077116975213),\n",
      " (3, 0.5081330240297587)]\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF\n",
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus) #This module implements functionality related to the Term Frequency - Inverse Document Frequency\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53435cd8-2275-4cc8-9f3e-e88323db3609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running LDA using Bag of Words\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b2f64ce-037b-460f-b2bd-ad8075a829d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.007*\"plan\" + 0.006*\"anti\" + 0.006*\"protest\" + 0.006*\"water\" + 0.006*\"firefight\" + 0.005*\"investig\" + 0.005*\"face\" + 0.005*\"court\" + 0.005*\"rain\" + 0.005*\"turkey\"\n",
      "Topic: 1 \n",
      "Words: 0.010*\"govt\" + 0.007*\"iraq\" + 0.007*\"fund\" + 0.007*\"race\" + 0.006*\"critic\" + 0.005*\"crean\" + 0.005*\"high\" + 0.005*\"patterson\" + 0.005*\"assur\" + 0.005*\"lead\"\n",
      "Topic: 2 \n",
      "Words: 0.014*\"plan\" + 0.009*\"polic\" + 0.009*\"crash\" + 0.007*\"rule\" + 0.007*\"charg\" + 0.007*\"australian\" + 0.005*\"injur\" + 0.005*\"say\" + 0.005*\"hous\" + 0.005*\"affect\"\n",
      "Topic: 3 \n",
      "Words: 0.009*\"urg\" + 0.008*\"water\" + 0.008*\"help\" + 0.008*\"public\" + 0.008*\"delay\" + 0.007*\"troop\" + 0.007*\"council\" + 0.007*\"probe\" + 0.007*\"protect\" + 0.006*\"hospit\"\n",
      "Topic: 4 \n",
      "Words: 0.011*\"face\" + 0.008*\"court\" + 0.007*\"call\" + 0.007*\"suppli\" + 0.007*\"rain\" + 0.006*\"trial\" + 0.006*\"hear\" + 0.006*\"action\" + 0.006*\"ahead\" + 0.006*\"melbourn\"\n",
      "Topic: 5 \n",
      "Words: 0.008*\"polic\" + 0.008*\"plan\" + 0.007*\"lead\" + 0.007*\"miss\" + 0.007*\"price\" + 0.006*\"consid\" + 0.006*\"land\" + 0.006*\"death\" + 0.006*\"cost\" + 0.006*\"battl\"\n",
      "Topic: 6 \n",
      "Words: 0.009*\"iraqi\" + 0.009*\"iraq\" + 0.007*\"polic\" + 0.005*\"seek\" + 0.005*\"call\" + 0.005*\"england\" + 0.005*\"station\" + 0.005*\"readi\" + 0.005*\"raid\" + 0.005*\"tent\"\n",
      "Topic: 7 \n",
      "Words: 0.010*\"death\" + 0.009*\"iraq\" + 0.008*\"rise\" + 0.008*\"club\" + 0.007*\"charg\" + 0.007*\"report\" + 0.007*\"match\" + 0.007*\"continu\" + 0.007*\"govt\" + 0.007*\"murder\"\n",
      "Topic: 8 \n",
      "Words: 0.012*\"claim\" + 0.008*\"charg\" + 0.007*\"concern\" + 0.007*\"probe\" + 0.007*\"warn\" + 0.006*\"stab\" + 0.006*\"polic\" + 0.006*\"group\" + 0.006*\"air\" + 0.005*\"educ\"\n",
      "Topic: 9 \n",
      "Words: 0.017*\"rain\" + 0.012*\"council\" + 0.011*\"drought\" + 0.011*\"break\" + 0.008*\"qanta\" + 0.006*\"continu\" + 0.006*\"iraq\" + 0.006*\"secur\" + 0.006*\"talk\" + 0.006*\"korean\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2df7d705-df1d-4331-9e59-27bdeacc1cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.006*\"govt\" + 0.005*\"price\" + 0.004*\"investig\" + 0.004*\"fuel\" + 0.004*\"hold\" + 0.004*\"predict\" + 0.003*\"struggl\" + 0.003*\"park\" + 0.003*\"contribut\" + 0.003*\"turkey\"\n",
      "Topic: 1 Word: 0.005*\"fund\" + 0.004*\"iraqi\" + 0.004*\"report\" + 0.004*\"decis\" + 0.004*\"protest\" + 0.004*\"hold\" + 0.004*\"charg\" + 0.003*\"pilot\" + 0.003*\"iraq\" + 0.003*\"warn\"\n",
      "Topic: 2 Word: 0.005*\"patterson\" + 0.004*\"elect\" + 0.004*\"kill\" + 0.004*\"polic\" + 0.004*\"turn\" + 0.003*\"player\" + 0.003*\"state\" + 0.003*\"rule\" + 0.003*\"protest\" + 0.003*\"telstra\"\n",
      "Topic: 3 Word: 0.005*\"kill\" + 0.004*\"work\" + 0.004*\"anti\" + 0.004*\"critic\" + 0.004*\"court\" + 0.004*\"nation\" + 0.003*\"protest\" + 0.003*\"worker\" + 0.003*\"claim\" + 0.003*\"turkey\"\n",
      "Topic: 4 Word: 0.006*\"nightclub\" + 0.005*\"rain\" + 0.005*\"polic\" + 0.004*\"land\" + 0.004*\"search\" + 0.004*\"council\" + 0.004*\"defenc\" + 0.004*\"warn\" + 0.004*\"talk\" + 0.004*\"claim\"\n",
      "Topic: 5 Word: 0.006*\"drought\" + 0.006*\"murder\" + 0.005*\"charg\" + 0.005*\"break\" + 0.005*\"stuttl\" + 0.004*\"polic\" + 0.004*\"rain\" + 0.004*\"court\" + 0.004*\"hous\" + 0.004*\"seat\"\n",
      "Topic: 6 Word: 0.005*\"record\" + 0.005*\"cairn\" + 0.004*\"brawl\" + 0.004*\"rain\" + 0.004*\"report\" + 0.004*\"iraq\" + 0.004*\"council\" + 0.004*\"river\" + 0.004*\"boost\" + 0.003*\"injur\"\n",
      "Topic: 7 Word: 0.005*\"rise\" + 0.005*\"miss\" + 0.005*\"plan\" + 0.005*\"expect\" + 0.004*\"suppli\" + 0.004*\"raid\" + 0.004*\"race\" + 0.004*\"murder\" + 0.004*\"warn\" + 0.004*\"club\"\n",
      "Topic: 8 Word: 0.004*\"reject\" + 0.004*\"iraq\" + 0.004*\"probe\" + 0.004*\"open\" + 0.004*\"famili\" + 0.003*\"council\" + 0.003*\"lead\" + 0.003*\"win\" + 0.003*\"levi\" + 0.003*\"northern\"\n",
      "Topic: 9 Word: 0.006*\"hospit\" + 0.004*\"ahead\" + 0.004*\"qanta\" + 0.004*\"stab\" + 0.004*\"break\" + 0.004*\"warn\" + 0.004*\"ethanol\" + 0.004*\"death\" + 0.003*\"remain\" + 0.003*\"plan\"\n"
     ]
    }
   ],
   "source": [
    "# Running LDA using TF-IDF\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4) # parallelized LDA\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45eec667-2578-4c51-b0a5-b81478c5a687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.8199659585952759\t \n",
      "Topic: 0.009*\"iraqi\" + 0.009*\"iraq\" + 0.007*\"polic\" + 0.005*\"seek\" + 0.005*\"call\" + 0.005*\"england\" + 0.005*\"station\" + 0.005*\"readi\" + 0.005*\"raid\" + 0.005*\"tent\"\n",
      "\n",
      "Score: 0.020007481798529625\t \n",
      "Topic: 0.007*\"plan\" + 0.006*\"anti\" + 0.006*\"protest\" + 0.006*\"water\" + 0.006*\"firefight\" + 0.005*\"investig\" + 0.005*\"face\" + 0.005*\"court\" + 0.005*\"rain\" + 0.005*\"turkey\"\n",
      "\n",
      "Score: 0.020006537437438965\t \n",
      "Topic: 0.010*\"death\" + 0.009*\"iraq\" + 0.008*\"rise\" + 0.008*\"club\" + 0.007*\"charg\" + 0.007*\"report\" + 0.007*\"match\" + 0.007*\"continu\" + 0.007*\"govt\" + 0.007*\"murder\"\n",
      "\n",
      "Score: 0.020006027072668076\t \n",
      "Topic: 0.017*\"rain\" + 0.012*\"council\" + 0.011*\"drought\" + 0.011*\"break\" + 0.008*\"qanta\" + 0.006*\"continu\" + 0.006*\"iraq\" + 0.006*\"secur\" + 0.006*\"talk\" + 0.006*\"korean\"\n",
      "\n",
      "Score: 0.020003627985715866\t \n",
      "Topic: 0.009*\"urg\" + 0.008*\"water\" + 0.008*\"help\" + 0.008*\"public\" + 0.008*\"delay\" + 0.007*\"troop\" + 0.007*\"council\" + 0.007*\"probe\" + 0.007*\"protect\" + 0.006*\"hospit\"\n",
      "\n",
      "Score: 0.02000330574810505\t \n",
      "Topic: 0.010*\"govt\" + 0.007*\"iraq\" + 0.007*\"fund\" + 0.007*\"race\" + 0.006*\"critic\" + 0.005*\"crean\" + 0.005*\"high\" + 0.005*\"patterson\" + 0.005*\"assur\" + 0.005*\"lead\"\n",
      "\n",
      "Score: 0.020002305507659912\t \n",
      "Topic: 0.012*\"claim\" + 0.008*\"charg\" + 0.007*\"concern\" + 0.007*\"probe\" + 0.007*\"warn\" + 0.006*\"stab\" + 0.006*\"polic\" + 0.006*\"group\" + 0.006*\"air\" + 0.005*\"educ\"\n",
      "\n",
      "Score: 0.020001957193017006\t \n",
      "Topic: 0.008*\"polic\" + 0.008*\"plan\" + 0.007*\"lead\" + 0.007*\"miss\" + 0.007*\"price\" + 0.006*\"consid\" + 0.006*\"land\" + 0.006*\"death\" + 0.006*\"cost\" + 0.006*\"battl\"\n",
      "\n",
      "Score: 0.020001426339149475\t \n",
      "Topic: 0.014*\"plan\" + 0.009*\"polic\" + 0.009*\"crash\" + 0.007*\"rule\" + 0.007*\"charg\" + 0.007*\"australian\" + 0.005*\"injur\" + 0.005*\"say\" + 0.005*\"hous\" + 0.005*\"affect\"\n",
      "\n",
      "Score: 0.020001374185085297\t \n",
      "Topic: 0.011*\"face\" + 0.008*\"court\" + 0.007*\"call\" + 0.007*\"suppli\" + 0.007*\"rain\" + 0.006*\"trial\" + 0.006*\"hear\" + 0.006*\"action\" + 0.006*\"ahead\" + 0.006*\"melbourn\"\n"
     ]
    }
   ],
   "source": [
    "#Performance evaluation by classifying sample document using LDA Bag of Words model\n",
    "processed_docs[10] #test document\n",
    "for index, score in sorted(lda_model[bow_corpus[10]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8f1359d-e274-4286-965c-d936e9b0bcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.8198614716529846\t \n",
      "Topic: 0.006*\"govt\" + 0.005*\"price\" + 0.004*\"investig\" + 0.004*\"fuel\" + 0.004*\"hold\" + 0.004*\"predict\" + 0.003*\"struggl\" + 0.003*\"park\" + 0.003*\"contribut\" + 0.003*\"turkey\"\n",
      "\n",
      "Score: 0.02003416419029236\t \n",
      "Topic: 0.005*\"record\" + 0.005*\"cairn\" + 0.004*\"brawl\" + 0.004*\"rain\" + 0.004*\"report\" + 0.004*\"iraq\" + 0.004*\"council\" + 0.004*\"river\" + 0.004*\"boost\" + 0.003*\"injur\"\n",
      "\n",
      "Score: 0.0200207456946373\t \n",
      "Topic: 0.004*\"reject\" + 0.004*\"iraq\" + 0.004*\"probe\" + 0.004*\"open\" + 0.004*\"famili\" + 0.003*\"council\" + 0.003*\"lead\" + 0.003*\"win\" + 0.003*\"levi\" + 0.003*\"northern\"\n",
      "\n",
      "Score: 0.020017843693494797\t \n",
      "Topic: 0.005*\"fund\" + 0.004*\"iraqi\" + 0.004*\"report\" + 0.004*\"decis\" + 0.004*\"protest\" + 0.004*\"hold\" + 0.004*\"charg\" + 0.003*\"pilot\" + 0.003*\"iraq\" + 0.003*\"warn\"\n",
      "\n",
      "Score: 0.020017601549625397\t \n",
      "Topic: 0.006*\"drought\" + 0.006*\"murder\" + 0.005*\"charg\" + 0.005*\"break\" + 0.005*\"stuttl\" + 0.004*\"polic\" + 0.004*\"rain\" + 0.004*\"court\" + 0.004*\"hous\" + 0.004*\"seat\"\n",
      "\n",
      "Score: 0.020013339817523956\t \n",
      "Topic: 0.005*\"patterson\" + 0.004*\"elect\" + 0.004*\"kill\" + 0.004*\"polic\" + 0.004*\"turn\" + 0.003*\"player\" + 0.003*\"state\" + 0.003*\"rule\" + 0.003*\"protest\" + 0.003*\"telstra\"\n",
      "\n",
      "Score: 0.02001296915113926\t \n",
      "Topic: 0.006*\"hospit\" + 0.004*\"ahead\" + 0.004*\"qanta\" + 0.004*\"stab\" + 0.004*\"break\" + 0.004*\"warn\" + 0.004*\"ethanol\" + 0.004*\"death\" + 0.003*\"remain\" + 0.003*\"plan\"\n",
      "\n",
      "Score: 0.02000896818935871\t \n",
      "Topic: 0.006*\"nightclub\" + 0.005*\"rain\" + 0.005*\"polic\" + 0.004*\"land\" + 0.004*\"search\" + 0.004*\"council\" + 0.004*\"defenc\" + 0.004*\"warn\" + 0.004*\"talk\" + 0.004*\"claim\"\n",
      "\n",
      "Score: 0.02000853791832924\t \n",
      "Topic: 0.005*\"rise\" + 0.005*\"miss\" + 0.005*\"plan\" + 0.005*\"expect\" + 0.004*\"suppli\" + 0.004*\"raid\" + 0.004*\"race\" + 0.004*\"murder\" + 0.004*\"warn\" + 0.004*\"club\"\n",
      "\n",
      "Score: 0.020004313439130783\t \n",
      "Topic: 0.005*\"kill\" + 0.004*\"work\" + 0.004*\"anti\" + 0.004*\"critic\" + 0.004*\"court\" + 0.004*\"nation\" + 0.003*\"protest\" + 0.003*\"worker\" + 0.003*\"claim\" + 0.003*\"turkey\"\n"
     ]
    }
   ],
   "source": [
    "#Performance evaluation by classifying sample document using LDA TF-IDF model.\n",
    "for index, score in sorted(lda_model_tfidf[bow_corpus[10]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9863ac34-e2b2-4283-8579-ff109bb867e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.525023341178894\t Topic: 0.008*\"polic\" + 0.008*\"plan\" + 0.007*\"lead\" + 0.007*\"miss\" + 0.007*\"price\"\n",
      "Score: 0.2748906910419464\t Topic: 0.012*\"claim\" + 0.008*\"charg\" + 0.007*\"concern\" + 0.007*\"probe\" + 0.007*\"warn\"\n",
      "Score: 0.02502259984612465\t Topic: 0.010*\"death\" + 0.009*\"iraq\" + 0.008*\"rise\" + 0.008*\"club\" + 0.007*\"charg\"\n",
      "Score: 0.02501627616584301\t Topic: 0.007*\"plan\" + 0.006*\"anti\" + 0.006*\"protest\" + 0.006*\"water\" + 0.006*\"firefight\"\n",
      "Score: 0.025012152269482613\t Topic: 0.010*\"govt\" + 0.007*\"iraq\" + 0.007*\"fund\" + 0.007*\"race\" + 0.006*\"critic\"\n",
      "Score: 0.025006990879774094\t Topic: 0.014*\"plan\" + 0.009*\"polic\" + 0.009*\"crash\" + 0.007*\"rule\" + 0.007*\"charg\"\n",
      "Score: 0.025006990879774094\t Topic: 0.009*\"urg\" + 0.008*\"water\" + 0.008*\"help\" + 0.008*\"public\" + 0.008*\"delay\"\n",
      "Score: 0.025006990879774094\t Topic: 0.011*\"face\" + 0.008*\"court\" + 0.007*\"call\" + 0.007*\"suppli\" + 0.007*\"rain\"\n",
      "Score: 0.025006990879774094\t Topic: 0.009*\"iraqi\" + 0.009*\"iraq\" + 0.007*\"polic\" + 0.005*\"seek\" + 0.005*\"call\"\n",
      "Score: 0.025006989017128944\t Topic: 0.017*\"rain\" + 0.012*\"council\" + 0.011*\"drought\" + 0.011*\"break\" + 0.008*\"qanta\"\n"
     ]
    }
   ],
   "source": [
    "#Testing model on unseen document\n",
    "unseen_document = 'How a Pentagon deal became an identity crisis for Google'\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad30c5b4-afca-4d15-961a-5a04fd2e9fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
